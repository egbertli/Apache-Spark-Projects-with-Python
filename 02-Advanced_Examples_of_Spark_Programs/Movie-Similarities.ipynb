{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITEM-BASED COLLABORATIVE FILTERING\n",
    "```\n",
    "Finding similar movies using Spark and the MovieLens data set\n",
    "\n",
    "Introducing caching RDD's\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find every pair of movies that were watched by the same person\n",
    "- Measure the similarity of their ratings across all users who watched both\n",
    "- Sort by movie, then by similarity strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn into Spark Problem\n",
    "- Map input ratings to (userID, (movieID, rating))\n",
    "- Find every movie pair rated by the same user\n",
    "- - This can be done with a 'self-join' operation\n",
    "- - At this point we have (userID, (movieID1, rating1), (movieID2, rating2))\n",
    "- Filter out duplicated pairs\n",
    "- Make the movie pairs the key\n",
    "- - map to (movieID1, movieID2), (rating1, rating2))\n",
    "- groupByKey() to get every rating pair found for each movie pair\n",
    "- Compute similarity between ratings for each movie in the pair\n",
    "- Sor, Save and display results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is some heavy lifting! Let's use every core of computer\n",
    "```python\n",
    "conf = SparkConf().setMaster('local[*]').setAppName('MovieSimilarities')\n",
    "sc = SparkContext(conf=conf)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CACHING RDD'S\n",
    "- In this example, we'll query the final RDD of movie similarities a couple of times\n",
    "- Any time you will perform more than one action on an RDD, you must cache it!\n",
    "- - Otherwise, Spark might re-evaluate the entire RDD all over again!\n",
    "- Use .cache() or .persist() to do this.\n",
    "- - What's the difference?\n",
    "- - Persisit() optionally lets you cache it to dist instead of just memory, just in case a node fails or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
